{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Deterministic Policy Gradient (DDPG)\n",
    "\n",
    "\n",
    "DDPG method uses two networks to learn the enviroment and to maximize the future reward in a system that may be controlled by means of actions represented in a continuous domain. The first network is called the Actor $A(w^a)$ (parameterized by $w^a$), this network takes the current state, of the agent, and outputs the best (according to the network) action. The second network is the called the Critic $C(w^c)$ (parameterized by $w^c$), this network is responsible to criticize the action taken by the Actor network. The ciritc network does that by taking the current state and the actions, chosen by the Actor, and outputs the q-value. The q-value indicates how favorable is would be to take the action when in the current state. \n",
    "\n",
    "As part of the training process of the network there are two different stages that repeats it self until the agent is deemed to have solved the enviroment\n",
    "\n",
    "* **Enviroment Interaction**: The agent interacting with the enviroment following the recommendations made by the Actor network\n",
    "\n",
    "* **Learn**: Updating the Actor/Critic networks using the agent's interactions\n",
    "\n",
    "\n",
    "In order to facilitate the training of the networks we have two sets of weights, for each network, ($w^a$, $w^c$) and ($w^a_{\\text{target}}$, $w^c_{\\text{target}}$), why that is will be introduced in the \"Learn\" section.\n",
    "\n",
    " \n",
    "###  Enviroment Interaction\n",
    "\n",
    "* Choose an action using the actor network's recommendations, i.e policy, after doing inference with the current state using paramters $w_a$. When we start to train the actor network the recommendations are not going to be good (i.e. the network might have been initilzed in such a way that it always outputs approximately the same policy) and we know that we should not trust them. So instead of always following the policy, we are only going to follow it in $1 - \\epsilon$ of the times, the rest of the times we are going to generate actions from a Ornsteinâ€“Uhlenbeck process. As the actor networks learns to output good policies, we decrese the $\\epsilon$ until we reach $\\epsilon_{end}$. Even if the network output good policies it's often favorable to have $\\epsilon_{end}$ not equal to zero, making the agent continue to explore the enviroment outside of the network's current understanding about what a good policy might be. \n",
    "\n",
    "\n",
    "* As the agent interacts with the enviroment we are continuously producing states $s_t$ actions $a_t$, rewards $r_t$ (that we got after we took the action) and new states $s_{t+1}$ (when we are transitioning from $s_t$ using $a_t$). We call this collection an experience tuple ($s_t$, $a_t$, $r_t$, $s_{t+1}$). This experience tuple is stored in a buffer that is later used when performing the \"Learn\" step. Together with the experience tuple we also store a measurment of how much novel information that is contained within the tuple, we call this $\\text{td-error}$ (it will be defined below). \n",
    "\n",
    "\n",
    "###  Learn\n",
    "\n",
    "* Sample a batch of experience tuples from the buffer ($s_t$, $a_t$, $r_t$, $s_{t+1}$)\n",
    "\n",
    "* Set a target for the critic network to learn, $y_t = r_t + \\gamma * C(s_{t+1}, a, w^c_{\\text{target}})$\n",
    "\n",
    "The target of the action $a_t$ when in state $s_t$ then becomes a weighted sum of the immediate reward (of taking action $a_t$) and the future expected reward, if we follow a greedy policy. The discount factor $\\gamma$ indicates how important future reward is compared to immediate reward in the target. When we construct the target we use $w_{\\text{target}}$ to parametrize the critic network, we do this to stabilize the learning that otherwise might become unstable due to correlations between the target and the network that undergoing learning.\n",
    "\n",
    "* Create the loss for the critic network that compares the target with the actual output from the network that undergoes learning \n",
    "\n",
    "$$ L_c = (C(s_t, a_t, w^c) - y_t)^2  = (C(s_t, a_t, w^c) - (r_t + \\gamma * C(s_{t+1}, a, w^c_{\\text{target}}))^2$$\n",
    "\n",
    "* Create the loss for the actor network with the objective to output actions that maximize the output (q-values) from the critic\n",
    "\n",
    "$$ L_a = - C(s_t, A(s_t, w_a), w_c) $$\n",
    "\n",
    "During the Enviroment Interaction step, before sending an experience tuple to the replaybuffer we calculate a $\\text{td-error}$, it's defined as \n",
    "\n",
    "$$\\text{td-error} = r_t + \\gamma * C(s_{t+1}, a_t+1, w^c) - c(s_{t}, a_t, w^c) $$\n",
    "\n",
    "and gives an indication about how suprised the network was by getting reward $r_t$ and having the q-value of the following state. We can then think of $\\text{td-error}$ as a proxy for how much novel information the experience tuple holds. During learning we want the network to focus on learning new things, so it makes sense to sample the tuples with high $\\text{td-error}$ more frequently than those with low  $\\text{td-error}$. In the replaybuffer we then set the probability of sample one tuple to be proportional to it's $\\text{td-error}$. This kind of method is called Prioritized Experience Replay. Importantly, each time we use the experience tuple we update the $\\text{td-error}$ in the replay buffer.\n",
    " \n",
    "* Update $C(w^c)$, $A(w^a)$ by minimization of $L_a$ and $L_c$  using gradient descent. \n",
    "\n",
    "* Update $C(w^c_{\\text{target}})$ and $A(w^a_{\\text{target}})$ weights by low-pass filter \n",
    "\n",
    "$$w^c_{\\text{target}} = \\tau \\times w^c_{\\text{target}} + (1 - \\tau) \\times w^c$$\n",
    "\n",
    "$$w^a_{\\text{target}} = \\tau \\times w^a_{\\text{target}} + (1 - \\tau) \\times w^a$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The networks consist of 3 hidden fully connected layers, 5 including the input and output layers. After each layer, except the output layer, layer normalization is used that normalizes the input across the nodes's output. ELU is used as activation function after each layer normalization.\n",
    "   \n",
    "### Critic    \n",
    "   \n",
    "    Fully connected - in 37 out 256  -> 256 nodes\n",
    "    Layer Normalization\n",
    "    ELU\n",
    "    \n",
    "    Fully connected - in 256 out 256 -> 256 nodes\n",
    "    Layer Normalization\n",
    "    ELU\n",
    "    \n",
    "    Fully connected - in 256 out 128 -> 128 nodes\n",
    "    Layer Normalization\n",
    "    ELU\n",
    "    \n",
    "    Fully connected - in 128 out 128  -> 128 nodes\n",
    "    Layer Normalization\n",
    "    ELU\n",
    "    \n",
    "    Fully connected - in 128 out 1   -> 1 nodes\n",
    "    \n",
    "    \n",
    "### Actor \n",
    "    \n",
    "    Fully connected - in 33 out 256  -> 256 nodes\n",
    "    Layer Normalization\n",
    "    ELU\n",
    "    \n",
    "    Fully connected - in 256 out 256 -> 256 nodes\n",
    "    Layer Normalization\n",
    "    ELU\n",
    "    \n",
    "    Fully connected - in 256 out 128 -> 128 nodes\n",
    "    Layer Normalization\n",
    "    ELU\n",
    "    \n",
    "    Fully connected - in 128 out 128  -> 128 nodes\n",
    "    Layer Normalization\n",
    "    ELU\n",
    "    \n",
    "    Fully connected - in 128 out 4   -> 1 nodes\n",
    "    Hyperbolic Tangent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 9 episodes was a score of +30 reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.Image(\"img/performance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters \n",
    "\n",
    "The name of the experiment, as seen in tensorboard\n",
    "    \n",
    "    experiement_name = \"final\"\n",
    "\n",
    "Size of the batches\n",
    "    \n",
    "    batch_size = 128\n",
    "\n",
    "Size of the replay bufffer\n",
    "    \n",
    "    replay_buffer_size = int(1e6)\n",
    "\n",
    "In the replay buffer we normalize the weights (w), associated with each replay tuplet, with the number of times (seen),\n",
    "the tuplet has been used for training. We then scale (w) with (seen) -> w <- w / seen ** beta.\n",
    "High beta -> we prefer to sample unseen tuples \n",
    "    \n",
    "    beta = 1\n",
    "\n",
    "In the replay buffer, after we have scaled the weights and converted it to a probability distribution (p) we scale the \n",
    "distribution, p.^beta_2. High beta_2 -> we will only sample tuples with high weight\n",
    "    \n",
    "    beta_2 = 2\n",
    "\n",
    "Number of episodes used for training\n",
    "    \n",
    "    episodes = 2000\n",
    "\n",
    "Gamma in the td-loss \n",
    "    \n",
    "    gamma = 0.99\n",
    "\n",
    "We have the possibility of scaling the reward with a factor\n",
    "    \n",
    "    scale_reward = 10\n",
    "\n",
    "Where do you want to run the inference/training, cuda or cpu \n",
    "    \n",
    "    device = \"cuda\"\n",
    "\n",
    "We wait (inference_steps), for each training episode, before we update the models\n",
    "    \n",
    "    inference_steps = 20\n",
    "\n",
    "When we start update the models we do that for (update_steps) \n",
    "Total number of training steps per episode (1000 / inference_steps) * update_steps\n",
    "    \n",
    "    update_steps = 45\n",
    "\n",
    "\n",
    "We randomly, with probability sigma, choose to use action generated from our noise-generator or to use \n",
    "the output from the actor-network\n",
    "\n",
    "    Start of sigma \n",
    "    sigma_init = 1\n",
    "    decay factor\n",
    "    sigma_decay = 0.86\n",
    "    stop of sigma\n",
    "    sigma_end = 0.1\n",
    "\n",
    " Ornsteinâ€“Uhlenbeck process \n",
    " \n",
    "    Ornsteinâ€“Uhlenbeck sigma \n",
    "    ou_sigma = 0.25\n",
    "\n",
    "Number of times we are running evaluation episodes (that we average over) after each training episode\n",
    "    \n",
    "    eval_rounds = 100\n",
    "\n",
    "Learning rates\n",
    "\n",
    "    lr_critic = 10**-4\n",
    "    lr_actor = 10**-4\n",
    "    Controls how we are updating the target network after each training step\n",
    "    tau_critic = 10**-3\n",
    "    tau_actor = 10**-3\n",
    "\n",
    "Number of output nodes in the first 2 layers\n",
    "    \n",
    "    hidden_dim = 256\n",
    "\n",
    "Number of output nodes in the following hidden layers\n",
    "\n",
    "    squeeze_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work\n",
    "\n",
    "#### Speed up training process\n",
    "\n",
    "* Run the batch processing in a seperat thread compared the model inference\n",
    "\n",
    "#### Fine tuning of hyperparamters\n",
    "   \n",
    "* Loop over a grid of hyperparameters, use tensorboard's hyperparamter tracking tool to narrow down a better set of hyperparamters \n",
    "\n",
    "#### Using historical state/action information when doing the inference\n",
    "\n",
    "* Use previous states leading up the agent's current state when doing the model inference. Also, add the actions taken during the previous steps\n",
    "\n",
    "#### Explore on-policy\n",
    "* A2C networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
